<?xml version="1.0" encoding="UTF-8"?>
<beans:beans xmlns="http://www.springframework.org/schema/hadoop"
	xmlns:beans="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:batch="http://www.springframework.org/schema/batch"
	xsi:schemaLocation="http://www.springframework.org/schema/batch http://www.springframework.org/schema/batch/spring-batch-2.1.xsd
		http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
		http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd">

	<batch:job id="job1">
		<batch:step id="import" next="wordcount">
			<batch:tasklet ref="script-tasklet"/>
		</batch:step>
			
		<batch:step id="wordcount">
			<batch:tasklet ref="wordcount-tasklet" />
		</batch:step>
	</batch:job>

	<tasklet id="wordcount-tasklet" job-ref="wordcount-job"/>

	<job id="wordcount-job" input-path="${wordcount.input.path:/user/gutenberg/input/word/}"
		output-path="${wordcount.output.path:/user/gutenberg/output/word/}" 
		mapper="org.apache.hadoop.examples.WordCount.TokenizerMapper"
		reducer="org.apache.hadoop.examples.WordCount.IntSumReducer"
		validate-paths="false" />

	<script-tasklet id="script-tasklet">
  	   <script language="groovy">
  	   	// 'hack' default permissions to make Hadoop work on Windows
		if (System.getProperty("os.name").startsWith("Windows")) {
			// 0655 = -rwxr-xr-x
			 org.apache.hadoop.mapreduce.JobSubmissionFiles.JOB_DIR_PERMISSION.fromShort((short) 0655);
			 org.apache.hadoop.mapreduce.JobSubmissionFiles.JOB_FILE_PERMISSION.fromShort((short) 0655);
		}

  	   
		inputPath = "${wordcount.input.path:/user/gutenberg/input/word/}"
		outputPath = "${wordcount.output.path:/user/gutenberg/output/word/}"	
		if (fsh.test(inputPath)) {
		  fsh.rmr(inputPath)
		}
		if (fsh.test(outputPath)) {
		  fsh.rmr(outputPath)
		}

		// copy using the streams directly (to be portable across envs)
		inStream = cl.getResourceAsStream("data/nietzsche-chapter-1.txt")
		org.apache.hadoop.io.IOUtils.copyBytes(inStream, fs.create(inputPath), cfg)
	  </script>	
    </script-tasklet>

</beans:beans>